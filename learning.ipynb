{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filePath</th>\n",
       "      <th>urgencyLevel</th>\n",
       "      <th>disasterLarge</th>\n",
       "      <th>disasterMedium</th>\n",
       "      <th>symptoms</th>\n",
       "      <th>triage</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68238</th>\n",
       "      <td>/hdd/data/088.위급상황_음성-음향_고도화_119_지능형_신고접수_음성_인...</td>\n",
       "      <td>상</td>\n",
       "      <td>구급</td>\n",
       "      <td>질병(중증 외)</td>\n",
       "      <td>['복통']</td>\n",
       "      <td>응급증상</td>\n",
       "      <td>수보자: 1, 119입니다. 신고자: 아, 여기 저희 아버지가 암 환자신데요 수보자...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62810</th>\n",
       "      <td>/hdd/data/088.위급상황_음성-음향_고도화_119_지능형_신고접수_음성_인...</td>\n",
       "      <td>하</td>\n",
       "      <td>구급</td>\n",
       "      <td>부상</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>신고자: 네, 아이가 놀다가 팔이 탈골이 된 거 같은데요. 수보자: 아 그래요? 계...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61283</th>\n",
       "      <td>/hdd/data/088.위급상황_음성-음향_고도화_119_지능형_신고접수_음성_인...</td>\n",
       "      <td>하</td>\n",
       "      <td>구급</td>\n",
       "      <td>질병(중증 외)</td>\n",
       "      <td>['요통']</td>\n",
       "      <td>잠재응급증상</td>\n",
       "      <td>수보자: 예, 119입니다. 신고자: 네, 여보세요. 수보자: 예, 말씀하세요. 신...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53628</th>\n",
       "      <td>/hdd/data/088.위급상황_음성-음향_고도화_119_지능형_신고접수_음성_인...</td>\n",
       "      <td>하</td>\n",
       "      <td>구급</td>\n",
       "      <td>질병(중증)</td>\n",
       "      <td>['복통', '기타통증', '호흡곤란', '그밖의통증기타', '어지러움']</td>\n",
       "      <td>잠재응급증상</td>\n",
       "      <td>수보자: 네, 119 상황실입니다. 신고자: 여보세요. 수보자: 여보세요. 신고자:...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103449</th>\n",
       "      <td>/hdd/data/088.위급상황_음성-음향_고도화_119_지능형_신고접수_음성_인...</td>\n",
       "      <td>중</td>\n",
       "      <td>구조</td>\n",
       "      <td>대물사고</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>신고자: 네, 119 수보자: 119입니다. 신고자: 예, 일로 양산동인데요. 수보...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 filePath urgencyLevel  \\\n",
       "68238   /hdd/data/088.위급상황_음성-음향_고도화_119_지능형_신고접수_음성_인...            상   \n",
       "62810   /hdd/data/088.위급상황_음성-음향_고도화_119_지능형_신고접수_음성_인...            하   \n",
       "61283   /hdd/data/088.위급상황_음성-음향_고도화_119_지능형_신고접수_음성_인...            하   \n",
       "53628   /hdd/data/088.위급상황_음성-음향_고도화_119_지능형_신고접수_음성_인...            하   \n",
       "103449  /hdd/data/088.위급상황_음성-음향_고도화_119_지능형_신고접수_음성_인...            중   \n",
       "\n",
       "       disasterLarge disasterMedium  \\\n",
       "68238             구급       질병(중증 외)   \n",
       "62810             구급             부상   \n",
       "61283             구급       질병(중증 외)   \n",
       "53628             구급         질병(중증)   \n",
       "103449            구조           대물사고   \n",
       "\n",
       "                                         symptoms  triage  \\\n",
       "68238                                      ['복통']    응급증상   \n",
       "62810                                          []     NaN   \n",
       "61283                                      ['요통']  잠재응급증상   \n",
       "53628   ['복통', '기타통증', '호흡곤란', '그밖의통증기타', '어지러움']  잠재응급증상   \n",
       "103449                                         []     NaN   \n",
       "\n",
       "                                                 dialogue  label  \n",
       "68238   수보자: 1, 119입니다. 신고자: 아, 여기 저희 아버지가 암 환자신데요 수보자...      2  \n",
       "62810   신고자: 네, 아이가 놀다가 팔이 탈골이 된 거 같은데요. 수보자: 아 그래요? 계...      2  \n",
       "61283   수보자: 예, 119입니다. 신고자: 네, 여보세요. 수보자: 예, 말씀하세요. 신...      1  \n",
       "53628   수보자: 네, 119 상황실입니다. 신고자: 여보세요. 수보자: 여보세요. 신고자:...      2  \n",
       "103449  신고자: 네, 119 수보자: 119입니다. 신고자: 예, 일로 양산동인데요. 수보...      2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/labeled_119.csv', index_col = 'Unnamed: 0')\n",
    "df['dialogue'] = df['dialogue'].str.replace('\\n', ' ', regex=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1497446/3609070347.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_train = df.groupby('label').apply(lambda x: x.sample(n=500, random_state=526))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>수보자: 입니다. 신고자: 네, 안녕하세요. 수보자: 네, 말씀하세요. 신고자: 저...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>수보자: 119입니다. 신고자: 네, 여기 현대 동궁아파트 신고자: [개인정보] 수...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>수보자: 네 여보세요. 신고자: 예 예예. 수보자: 예, 가고 있는데 사람은 다 나...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>수보자: 네 119입니다. 신고자: 예, 안녕하세요. 여기 강남구 대치동, 신고자:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>수보자: 네, 119입니다. 신고자: 여보세요? 수보자: 네 신고자: 아, 저희 집...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dialogue  label\n",
       "0  수보자: 입니다. 신고자: 네, 안녕하세요. 수보자: 네, 말씀하세요. 신고자: 저...      0\n",
       "1  수보자: 119입니다. 신고자: 네, 여기 현대 동궁아파트 신고자: [개인정보] 수...      0\n",
       "2  수보자: 네 여보세요. 신고자: 예 예예. 수보자: 예, 가고 있는데 사람은 다 나...      0\n",
       "3  수보자: 네 119입니다. 신고자: 예, 안녕하세요. 여기 강남구 대치동, 신고자:...      0\n",
       "4  수보자: 네, 119입니다. 신고자: 여보세요? 수보자: 네 신고자: 아, 저희 집...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 각 라벨에서 500개씩 샘플링\n",
    "df_train = df.groupby('label').apply(lambda x: x.sample(n=500, random_state=526))\n",
    "\n",
    "df_train = df_train[['dialogue', 'label']]\n",
    "# 인덱스 초기화\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1497446/3024197611.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_test = df.groupby('label').apply(lambda x: x.sample(n=50, random_state=526))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>수보자: 입니다. 신고자: 네, 안녕하세요. 수보자: 네, 말씀하세요. 신고자: 저...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>수보자: 119입니다. 신고자: 네, 여기 현대 동궁아파트 신고자: [개인정보] 수...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>수보자: 네 여보세요. 신고자: 예 예예. 수보자: 예, 가고 있는데 사람은 다 나...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>수보자: 네 119입니다. 신고자: 예, 안녕하세요. 여기 강남구 대치동, 신고자:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>수보자: 네, 119입니다. 신고자: 여보세요? 수보자: 네 신고자: 아, 저희 집...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dialogue  label\n",
       "0  수보자: 입니다. 신고자: 네, 안녕하세요. 수보자: 네, 말씀하세요. 신고자: 저...      0\n",
       "1  수보자: 119입니다. 신고자: 네, 여기 현대 동궁아파트 신고자: [개인정보] 수...      0\n",
       "2  수보자: 네 여보세요. 신고자: 예 예예. 수보자: 예, 가고 있는데 사람은 다 나...      0\n",
       "3  수보자: 네 119입니다. 신고자: 예, 안녕하세요. 여기 강남구 대치동, 신고자:...      0\n",
       "4  수보자: 네, 119입니다. 신고자: 여보세요? 수보자: 네 신고자: 아, 저희 집...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 각 라벨에서 500개씩 샘플링\n",
    "df_test = df.groupby('label').apply(lambda x: x.sample(n=50, random_state=526))\n",
    "\n",
    "df_test = df_test[['dialogue', 'label']]\n",
    "# 인덱스 초기화\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work_space/emerg_classifi/.emerg_classifi/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert pandas DataFrame to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "test_dataset = Dataset.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'klue/bert-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Load KoBERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=3)  # Assuming 3 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이어 고정하기\n",
    "for name, param in model.named_parameters():\n",
    "    if \"bert.embeddings\" in name:\n",
    "        param.requires_grad = False  # 임베딩 레이어 고정\n",
    "    elif \"bert.encoder.layer.\" in name:\n",
    "        layer_num = int(name.split(\".\")[3])  # 레이어 번호 추출\n",
    "        if layer_num <= 6:  # 0-5 레이어 고정\n",
    "            param.requires_grad = False\n",
    "        else:  # 6-11 레이어 학습 가능\n",
    "            param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = True  # 풀링 레이어 및 분류기는 학습 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1500/1500 [00:03<00:00, 426.16 examples/s]\n",
      "Map: 100%|██████████| 150/150 [00:00<00:00, 447.26 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['dialogue'], padding='max_length', truncation=True)\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# 평가를 위한 지표 계산 함수 정의\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)  # 예측된 클래스 가져오기\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/work_space/emerg_classifi/.emerg_classifi/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "# from torch.optim import AdamW\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/240 04:54, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.058200</td>\n",
       "      <td>0.936544</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.616063</td>\n",
       "      <td>0.654002</td>\n",
       "      <td>0.613333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.884200</td>\n",
       "      <td>0.740516</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.643345</td>\n",
       "      <td>0.641151</td>\n",
       "      <td>0.653333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.779300</td>\n",
       "      <td>0.704988</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.653155</td>\n",
       "      <td>0.674501</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.728100</td>\n",
       "      <td>0.640812</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.667611</td>\n",
       "      <td>0.693815</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.681900</td>\n",
       "      <td>0.609205</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.731632</td>\n",
       "      <td>0.731158</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.642600</td>\n",
       "      <td>0.540569</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.771405</td>\n",
       "      <td>0.771395</td>\n",
       "      <td>0.773333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.626100</td>\n",
       "      <td>0.521414</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800559</td>\n",
       "      <td>0.807019</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.597600</td>\n",
       "      <td>0.499275</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.801024</td>\n",
       "      <td>0.804069</td>\n",
       "      <td>0.806667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.568400</td>\n",
       "      <td>0.486429</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.809810</td>\n",
       "      <td>0.810321</td>\n",
       "      <td>0.813333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.570500</td>\n",
       "      <td>0.475823</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.803351</td>\n",
       "      <td>0.803810</td>\n",
       "      <td>0.806667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=240, training_loss=0.7136807362238566, metrics={'train_runtime': 296.5056, 'train_samples_per_second': 50.589, 'train_steps_per_second': 0.809, 'total_flos': 3946701265920000.0, 'train_loss': 0.7136807362238566, 'epoch': 10.0})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer, EarlyStoppingCallback\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,  # 지표 계산 함수 추가\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 2)]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.47582340240478516, 'eval_accuracy': 0.8066666666666666, 'eval_f1': 0.8033507292921184, 'eval_precision': 0.8038095238095238, 'eval_recall': 0.8066666666666666, 'eval_runtime': 1.5055, 'eval_samples_per_second': 99.632, 'eval_steps_per_second': 1.993, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# 평가를 위한 지표 계산 함수 정의\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)  # 예측된 클래스 가져오기\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# 평가\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# 평가 결과 출력\n",
    "print(\"Evaluation Results:\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./saved_model/tokenizer_config.json',\n",
       " './saved_model/special_tokens_map.json',\n",
       " './saved_model/vocab.txt',\n",
       " './saved_model/added_tokens.json')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_dir = './saved_model'\n",
    "# 모델 저장\n",
    "model.save_pretrained(output_dir)\n",
    "# 토크나이저 저장\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
